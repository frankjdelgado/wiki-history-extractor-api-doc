\section{Marco Aplicativo}

\subsection{Método de Desarrollo}

Para llevar a cabo el cumplimiento de los objetivos, es necesario definir un esquema o metodología de trabajo que permita la elaboración de un conjunto de
lineamientos de manera estructurada y organizada.
Por lo tanto, se hace uso de el método de Desarrollo Rápido de Aplicaciones (RAD), el cual permite la iteración rápida y continua de pequeños objetivos para alcanzar la meta final.

RAD es un proceso de desarrollo de software que
integra un conjunto de técnicas, lineamientos y herramientas que permiten llevar a cabo, en
cortos periodos de tiempo, la implementación de funcionalidades en un sistema, de tal manera que
satisfacen las necesidades del cliente \cite{23}.
Siguiendo esta metodología, el software evoluciona y crece durante el proceso de desarrollo en base a la retro alimentación que se tiene con el cliente.
De esta manera, se realizan múltiples entregas de una tarea que
contiene las nuevas funcionalidades esperadas.
Cada una de estas tareas cuenta con instrumento de documentación al cuál llamaremos historias.
Estas historias describen los detalles técnicos e categorizan las tareas en subgrupos.

Por medio de RAD, fue posible la implementación de la solución al problema previamente planteado a través del desarrollo de múltiples componentes relacionados entre si, para
brindar un servicio web como un API.
La figura \ref{fig:diagram_general} muestra la arquitectura general del servicio web, y como interactuá con las aplicaciones clientes que lo consumen.

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/diagram_general}
	\caption{Arquitectura general de la aplicación}
	\label{fig:diagram_general}
\end{figure}

Los componentes que conforman este servicio son los siguientes

\begin{itemize}

\item Un servidor web (Nginx) que atiende, en primera instancia, las peticiones de las aplicaciones clientes y balancea la carga entre múltiple nodos que almacenan el API.

\item Una o más aplicaciones Flask, almacenadas en máquinas separadas, que ejecutan el API e inician las tareas de consulta y extracción de revisiones.

\item Un servicio de mensajería (RabbitMQ) que recibe las tareas iniciadas por el API
y las encola para su posterior ejecución.

\item Uno o más nodos que ejecutan un proceso trabajador de Celery para la ejecución de las tareas almacenadas en RabbitMQ.
Estos nodos mantienen una comunicación con RabbitMQ para actualizar el estado y progreso de las tareas.

\item Y, por último, un componente de almacenamiento de artículos wiki y sus revisiones. Para ello se hace uso de MongoDB y está implementado como un cluster de base de datos distribuidos
entre múltiples máquinas conectadas entre sí que permiten la fragmentación de los datos.

\end{itemize}

\subsection{Servidor Web}

El servidor web que atiende las solicitudes en primera instancia es Nginx,
el cual funciona como un intermediario entre el cliente y el API que responde dicha solicitud.
Nginx permite balancear la carga de trabajo entre múltiples servidores que contienen la aplicación mediante el algoritmo de round robin,
de tal forma que cada servidor es utilizado de forma equitativa, tal como se muestra en la figura \ref{fig:round_robin}.

\begin{figure}[H]
	\centering
		\includegraphics[width=0.9\textwidth]{figures/round_robin}
	\caption{Algoritmo de distribución de peticiones de Nginx basado en método de Round Robin.}
	\label{fig:round_robin}
\end{figure}

Una vez la petición ha sido reasignada, es atendida por medio del servidor web UWSGI, y en conjunto
con Flask y el resto de las tecnologías incluidas en el API, genera una respuesta de vuelta al cliente.

\subsection{API}

El API diseñado para realizar las labores de extracción y consulta de las revisiones, hace uso del lenguaje de programación Python \texttt{2.7.10} y el uso del framework Flask \texttt{v0.12}.
Ambas tecnologías permiten la asignación de rutas específicas para cada módulo
y la atención de peticiones.

La interacción entre el servicio y una aplicación cliente puede ser apreciada en la figura \ref{fig:diagram_api_1}.

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/diagram_api_1}
	\caption{Interacción entre una aplicación cliente y el API}
	\label{fig:diagram_api_1}
\end{figure}

Esta interacción se basa en la petición de un recurso o de un proceso, por parte de una aplicación cliente, a una ruta del servidor web (endpoint).
Cada petición puede incluir parámetros opcionales para la paginación, filtrado de resultados, como por ejemplo, el idioma del artículo a extraer.

Las rutas de acceso que ofrece el API son las siguientes:

\begin{itemize}
	\item \texttt{/api/v1/articles}. Listado de todos los artículos extraídos.
	\item \texttt{/api/v1/revisions}. Listado de las revisiones de los artículos extraídos.
	\item \texttt{/api/v1/extract}. Extracción de revisiones de artículos wiki.
	\item \texttt{/api/v1/avg}. Cálculo del promedio de revisiones de un artículo por rango fechas.
	\item \texttt{/api/v1/count}. Cálculo de número de revisiones de un artículo por fecha.
	\item \texttt{/api/v1/mode}. Cálculo de las revisiones mas extraídas por rango de fecha.
	\item \texttt{/api/v1/status}. Indica el estado del proceso de extracción.
	\item \texttt{/api/v1/query}. Permite la ejecución de consultas personalizadas a la base de datos.
\end{itemize}

\subsubsection{Extracción de Historiales}

Para la extracción de historiales se hace uso de la ruta de acceso \texttt{/api/v1/extract}, la cual
tiene como parámetros:
\texttt{title}, que se refiere al título del del artículo; \texttt{url}, representa la ruta completa de un artículo, por ejemplo:
\texttt{https://en.wikipedia.org/wiki/The\_Lord\_of\_the\_Rings}; y por último, \texttt{locale}, el cual índica el idioma del artículo y
es completamente opcional, puesto que el sistema asume el inglés como lenguaje por defecto o lo extrae del parámetro
\texttt{url}.
Es necesario proporcionar el parámetro \texttt{url} o \texttt{title} de forma obligatoria para poder llevar a cabo la extracción.

En la figura \ref{fig:extract_url_format} se puede apreciar dos ejemplos del uso de los parámetros \texttt{url}, \texttt{title} y \texttt{locale}:

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/extract_url_format}
	\caption{Parámetros para la extracción de historiales}
	\label{fig:extract_url_format}
\end{figure}

La ejecución de esta tarea se lleva a cabo por medio de Celery y RabbitMQ.
Con estas tecnologías, múltiples computadores ejecutan un proceso de Celery, los
cuales están conectados entre si gracias a RabbitMQ, escuchando constantemente los mensajes entrantes de este servicio.
Una vez recibida la petición por el API, se genera una tarea de extracción por medio de Celery, la cual tiene un identificador único. Esta tarea es encolada en una lista de
espera que es atendida por uno de los trabajadores conectados a RabbitMQ y es ejecutada en segundo plano.
Posteriormente, el API crea una respuesta a la petición generando una ruta para consultar el progreso
del proceso de extracción, la cual luce como se muestra en la figura \ref{fig:extract_response}:

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/extract_response}
	\caption{Respuesta a una petición de extracción de historiales de un artículo}
	\label{fig:extract_response}
\end{figure}

Durante el proceso de extracción, se realizan peticiones hacia el API de Wikipedia.
Se toma como URL por defecto la dirección https://en.wikipedia.org/w/api.php, en conjunto con diversos parámetros, tales como:

\begin{itemize}
	\item \textbf{action}: tipo de petición que se realiza sobre este API, en este caso se hace uso del valor \texttt{query} para indicar que solo se realizará una consulta.

	\item \textbf{format}: formato de la respuesta obtenida, la cual puede ser XML o JSON.

	\item \textbf{props}: la propiedad del artículo al cual se desea consultar, en este caso se usa el valor \texttt{revisions} para poder extraer el historial de modificaciones del mismo.

	\item \textbf{rvprop}: atributos de la propiedad extraída, los incluidos para esta extracción son los siguientes: ids, flags, timestamp, user, userid, size, sha1, contentmodel, comment, parsedcomment, content, tags.

	\item \textbf{rvlimit}: permite la paginación de los resultados e indica la cantidad de resultados que se quieren obtener por página.

	\item \textbf{newer}: permite ordenar las revisiones de forma ascendente o descendiente acorde a la fecha de creación. Se ordenan de forma descendente usando el valor \texttt{newer}, de esta manera es más rápido extraer las revisiones mas recientes.
\end{itemize}

Justo antes de enviar la solicitud al API de wikipedia, se verifica que el artículo a consultar ya esté almacenado en la base de datos, en caso de no estarlo, se almacena indicando la fecha de extracción.
Posteriormente, se extraen sus revisiones, y puesto que la respuesta del API coloca las revisiones mas recientes al principio, el extractor culmina su ejecución una vez determina que alcanzó una revisión que ya ha sido almacenada.
Al almacenar las revisiones en la base de datos, se actualiza el documento del artículo con la fecha de la última extracción y el identificador de la revisión extraída, y por último, se actualiza el progreso de la tarea.

En la figura \ref{fig:response_status} se puede apreciar un ejemplo de la consulta del progreso de las tareas:

\begin{figure}[H]
	\centering
		\includegraphics[width=0.8\textwidth]{figures/response_status}
	\caption{Respuesta a una petición para consultar de progreso de una tarea de extracción}
	\label{fig:response_status}
\end{figure}

La tabla \ref{tab:extract} muestra la historia asociada a la extracción de revisiones.

\input{tables/extract}

\subsubsection{Consultas}

El API consta de métodos de acceso para consultar las revisiones extraídas y
los artículos asociados a través de las rutas \texttt{/api/v1/revisions} y \texttt{/api/v1/articles} respectivamente.

En estas rutas de consulta es posible hacer uso de diversos parámetros de búsqueda,
entre ellas están: los parámetros de paginación \texttt{page} y \texttt{page\_size},
y los parámetros de búsqueda que corresponden a los atributos del artículo,
tales como: \texttt{title}, \texttt{first\_extraction\_date}, \texttt{last\_extraction\_date}, \texttt{last\_revision\_extracted} y \texttt{locale}.
Adicionalmente, existe el parámetro \texttt{sort}, que permite ordenar los resultados a través del valor de un atributo de la colección a consultar, ejemplo, por la fecha de extracción de un artículo.

La ruta \texttt{articles} tiene como finalidad mostrar la información pertinente a los artículos que han sido extraídos a través del API, para lo cual se realiza una consulta a la colección \texttt{articles} almacenada en la base de datos. Un ejemplo de la respuesta obtenida por esta ruta puede ser apreciada en la figura \ref{fig:response_articles}.

\begin{figure}[H]
	\centering
		\includegraphics[width=0.8\textwidth]{figures/response_articles}
	\caption{Respuesta a una petición de consulta de artículos}
	\label{fig:response_articles}
\end{figure}

Por su parte, la ruta \texttt{revisions} permite consultar el contenido y los datos pertinentes a las revisiones que han sido extraídas.
En la figura \ref{fig:response_revisions} se puede apreciar una respuesta del servidor a la consulta de revisiones.

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/response_revisions}
	\caption{Respuesta a una petición de consulta de revisiones}
	\label{fig:response_revisions}
\end{figure}

Adicionalmente, existen mas rutas de acceso al API para la consulta de diversas métricas predefinidas, tales como: promedio, conteo de revisiones y moda.

Durante el cálculo de estas métricas se toman como parámetros múltiples atributos, tales como: el título del artículo o la fecha de extracción.
Dichos atributos son usados para reducir o filtrar las revisiones que se van a consultar en el cálculo de  métricas.

Antes de que los parámetros de búsqueda sean utilizados, pasan por un proceso de aceptación, en donde sólo son tomados en cuenta aquellos parámetros incluidos en una lista denominada \textit{Lista Blanca}, mientras que el resto son ignorados.

Posteriormente, se genera una tarea que será procesada en segundo plano por medio de Celery, con el tipo de consulta a realizar y los parámetros de búsqueda.

El formato de algunos atributos utilizados en el proceso de búsqueda de revisiones o artículos, tales como, fecha de extracción y tamaño de la revisión, es alterado para facilitar la consulta de revisiones por un rango o intervalo determinado.
Para los atributos que representan una fecha, se condiciona la búsqueda en base a una fecha única o un intervalo de fechas por medio de los parámetros recibidos en la petición.
Para atributos que representan el tamaño se ejecuta un proceso similar, donde se considera un segundo argumento opcional que indica intervalo a evaluar para condicinar la consulta.

En la tabla \ref{tab:count} se puede apreciar, con detalle, y por medio de su historia, las condiciones de búsqueda aceptadas por dicha consulta.

\input{tables/count}

La consulta del promedio revisiones se calcula haciendo uso de intervalos de tiempos (en este caso, días), determinados por el usuario en la petición al servicio.
En la tabla \ref{tab:average} se presentan con mayor con detalle, por medio de su historia, los filtros aceptados, así como los argumentos obligatorios de la consulta.

\input{tables/average}

Las consultas sobre la ruta \texttt{/api/v1/mode} permiten calcular el valor de un atributo con mayor frecuencia.
Dicha consulta se realiza sobre un conjunto de revisiones que pueden ser filtradas con parámetros de búsqueda, los cuales pueden ser apreciados en la tabla \ref{tab:mode}.
Este tipo de consulta permite, por ejemplo, calcular cuál es el mayor contribuyente a un artículo en un año determinado.

\input{tables/mode}

Por último, el API provee la ruta \texttt{/api/v1/query} que permite ejecutar consultas a la base de datos directamente de los parámetros recibidos por la petición.
El cuerpo de las peticiones realizadas sobre esta ruta debe tener un formato JSON, en conjunto con el atributo de cabecera
\texttt{content-type} que debe tener como valor \texttt{application/json}.
La estructura del cuerpo de la petición debe coincidir con el formato aceptado para la creación de consultas por medio de PyMongo.
Un ejemplo de este formato puede ser apreciado en la figura \ref{fig:query_body_format}, en donde cada clave de la dupla clave-valor del archivo JSON representa una función de agregación valida de MongoDB:

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/query_body_format}
	\caption{Estructura del cuerpo de la petición a la ruta /api/v1/query}
	\label{fig:query_body_format}
\end{figure}

Adicionalmente, la ruta permite especificar la colección de la base de datos a la cual consultar, y de forma opcional,
el formato de fecha de alguna columna en caso de ser necesario.
Un ejemplo, del uso de estos parámetros es el que se muestra en la figura \ref{fig:query_url}, en donde se realiza una consulta de la colección llamada \texttt{revisions}

\begin{figure}[H]
	\centering
		\includegraphics[width=1\textwidth]{figures/query_url}
	\caption{Estructura del cuerpo de la petición a la ruta /api/v1/query}
	\label{fig:query_url}
\end{figure}

Por medio de esta ruta es posible realizar cualquier tipo de consulta sobre la base de datos, y así, obtener métricas
adicionales para su análisis posterior. En la tabla \ref{tab:query} se puede ver mas detalles con respecto a los parámetros.

\input{tables/query}


\input{chapters/revisit}

\subsection{Almacenamiento}

Como fue mencionado en el Capítulo 2, la base de datos utilizada para almacenar las revisiones y artículos wiki es MongoDB.
A través del proceso de extracción se almacenan dos colecciones:
\texttt{revisions}, que representa las revisiones o historial de modificaciones del artículo wiki;
y \texttt{articles}, que se refiere a los artículos de dichas revisiones.
La arquitectura elegida para esta solución contiene la cantidad de elementos mínimos para implementar un cluster de base de datos en MongoDB, y cuenta con: dos sets de réplicas de shards, un set de réplicas para el servidor de configuración, y por último, un servidor de consultas.

La tabla \ref{tab:database} representa la historia asociada al almacenamiento de los datos en MongoDB.

\input{tables/database}

Las colecciones están distribuidas entre dos fragmentos o shards que contienen un subgrupo de los datos fragmentados en el cluster, y la unión de estos subgrupos conforman la totalidad de los datos almacenados por la aplicación.
Esta separación de los datos puede ser apreciada en la figura \ref{fig:sharded_database}.

\begin{figure}[H]
	\centering
		\includegraphics[width=0.4\textwidth]{figures/sharded_database}
	\caption{División de la base de datos en subgrupos}
	\label{fig:sharded_database}
\end{figure}

Cada uno de estos subgrupos está siendo almacenado un servidor físico diferente, garantizando el escalamiento horizontal, tal como lo demuestra la figura \ref{fig:shards_distributed},
Para la creación de estos grupos, el sharding se lleva a cabo a través del Hashed Sharding, de esta manera es
posible alcanzar una distribución homogénea de los datos entre los servidores.

\begin{figure}[H]
	\centering
		\includegraphics[width=0.5\textwidth]{figures/shards_distributed}
	\caption{Shards de la base de datos distribuidos físicamente}
	\label{fig:shards_distributed}
\end{figure}

Para poder crear un shard es necesario que este pertenezca a un set de réplica de un mínimo de tres miembros,
por lo tanto, por cada shard se tienen tres servidores físicos que permiten la replicación de ese subgrupo de datos, garantizando
así la alta disponibilidad de los mismos.
Para poder fragmentar la base de datos, se necesita de un mínimo de dos shards, por lo que se tiene un total mínimo de 6 servidores
que solo cumplen las labores de fragmentación y replicación.

Para poder coordinar las funciones de estos shards, como la autenticación, almacenamiento de los meta datos y consultas sobre el cluster de shards,
es necesario hacer uso del servicio de un servidor de configuración.
Este servidor, al igual que los shards, debe pertenecer a un grupo de réplicas, sumando tres servidores físicos mas, que ademas,
tienen la capacidad de recuperarse en caso de fallos, y nuevamente, permitir la alta disponibilidad.

Finalmente, se tiene un último servidor de base de datos cuya única labor es la ejecución de operaciones de lectura y escritura sobre la base de datos.
Este servidor es denominado servidor de consultas y no es necesaria su replicación.
Las aplicaciones clientes que deseen realizar alguna consulta sobre la base de datos, realizan sus peticiones únicamente a este servidor.
Así mismo, una vez es recibida la petición de consulta, este se comunica con servidor de configuración para que este le brinde apoyo a la hora de ejecutar las operaciones.
Con este último servidor, el conteo total de servidores de MongoDB para está arquitectura es de diez nodos.

La figura \ref{fig:mongo_cluster}, que se muestra a continuación, demuestra el diagrama de la arquitectura del cluster de base de datos implementado:

\begin{figure}[H]
	\centering
		\includegraphics[width=0.9\textwidth]{figures/mongo_cluster}
	\caption{Arquitectura del cluster de base de datos}
	\label{fig:mongo_cluster}
\end{figure}

En tabla \ref{tab:cluster} se puede apreciar la historia asociada a la configuración del cluster de MongoDB.

\input{tables/cluster}

\subsection{Docker}

Para poder poner en funcionamiento esta aplicación distribuida y el cluster de la base de datos, se hace uso de la herramienta Docker.
Docker permite levantar servicios que emulan un servidor físico, los cuales pueden ser conectados en una red para que puedan comunicarse y llevar a cabo todas las tareas de extracción y consultas.

Adicionalmente, permite generar ambientes tanto de producción como de desarrollo, en este caso, se hace uso de la versión \texttt{17.12.0-ce} en conjunto con Docker-Compose para facilitar el levantamiento de los servicios en ambos ambientes.

En la tabla \ref{tab:docker}, que se presenta a continuación, se puede apreciar la historia asociada al uso de docker para el levantamiento de la aplicación.

\input{tables/docker}

En primera instancia se genera una imagen para la aplicación flask, los trabajadores de Celery y el resto de los servicios.
El nombre de las imágenes está definido bajo el siguiente formato: \texttt{nombre:version}, y pueden ser generadas por medio de un archivo llamado Dockerfile, cuyo contenido puede ser apreciado a continuación:

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=docker,caption={Contenido del archivo Dockerfile para la imagen del API},breaklines=true,label={code:dockerfile}]
# Dockerfile
FROM python:2.7-alpine

RUN mkdir /app
WORKDIR /app

COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt

COPY . .

CMD python manage.py runserver --host 0.0.0.0 --port=80
\end{lstlisting}
\end{minipage}

Para los servicios de Nginx, RabbitMQ y MongoDB se hace uso de imágenes provenientes del repositorio oficial llamado Docker Hub,
las imágenes utilizadas son las siguientes: \texttt{rabbitmq:3.6.11}, \texttt{mongo:3.6.2} y \texttt{nginx:1.13.3}.

La configuración de los contenedores se realiza a través del archivo \texttt{docker-compose.yml}, en el cual se especifican
las imágenes a utilizar por cada servicio, variables de entorno, nombre de la red, entre otros.

Las imágenes de RabbitMQ y MongoDB tienen la característica que permite utilizar variables de entorno para establecer el usuario y clave de acceso sin ningún tipo de configuración manual por parte del desarrollador,
por lo tanto, las credenciales usadas para ambos servicios son agregadas en el archivo \texttt{docker-compose.yml} para restringir su acceso.
Por ejemplo, para RabbitMQ las credenciales son las siguientes: \verb|RABBITMQ_DEFAULT_USER=wiki| y \verb|RABBITMQ_DEFAULT_PASS=wiki123|.
Adicionalmente, se establecieron una serie reglas adicionales, como por ejemplo,
declaración de volúmenes para mantener la persistencia de datos y
la exposición de los puertos de RabbitMQ, MongoDB y Nginx;
lo cual permite a las aplicaciones externas acceder a estos servicios, y en el caso de Nginx, permite que otras aplicaciones puedan ejecutar peticiones al API.

Parte de la configuración de los servicios y contendedores de Docker puede ser apreciada a continuación:

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=docker-compose-2,caption={Declaración de servicios con Docker Compose},breaklines=true,label={code:dockercompose}]
version: '3'

services:

    rabbit:
        image: rabbitmq:3.6.11
        restart: always
        hostname: rabbit
        environment:
            - RABBITMQ_DEFAULT_USER=wiki
            - RABBITMQ_DEFAULT_PASS=wiki123
        ports:
            - "5673:5672"
        networks:
            - wiki_network
        volumes:
            - 'wiki_rabbit:/data'
\end{lstlisting}
\end{minipage}
